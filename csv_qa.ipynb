{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da8c8d70-38da-4d8a-9c61-e001452ea9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip uninstall [options] <package> ...\n",
      "  pip uninstall [options] -r <requirements file> ...\n",
      "\n",
      "no such option: -Y\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall langchain -Y\n",
    "!pip install -q langchain==0.3.22 langchain-aws==0.2.18 langchain-community==0.3.20 langchain-core==0.3.49 langchain-experimental==0.3.4 langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1b9120-0341-4a82-96bc-d9b3ca757c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "import pydantic\n",
    "\n",
    "\n",
    "# Initialize BedrockChat model\n",
    "llm = init_chat_model(\n",
    "    \"amazon.nova-pro-v1:0\",\n",
    "    model_provider=\"bedrock\",\n",
    "    model_kwargs={'temperature': 0.7}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276156d7-6693-4be3-9f2b-7ef9e9bf04c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.204207968574636"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "tool = PythonAstREPLTool(locals={\"df\": df})\n",
    "tool.invoke(\"df['Fare'].mean()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f0af87-9d0b-4c6b-abe3-e497437ab0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=[{'type': 'tool_use', 'name': 'python_repl_ast', 'input': {'query': \"import pandas as pd\\ndf = pd.DataFrame({'Age': [22, 35, 45, 29, 31], 'Fare': [7.25, 14.5, 31.0, 7.925, 26.55]})\\ndf['Age'].corr(df['Fare'])\"}, 'id': 'tooluse_Pdt6-wMOSMmjtVCaLseKPQ'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '91363bf8-0fc1-4acd-babe-4539c6215aea', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 21 May 2025 22:03:58 GMT', 'content-type': 'application/json', 'content-length': '416', 'connection': 'keep-alive', 'x-amzn-requestid': '91363bf8-0fc1-4acd-babe-4539c6215aea'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [934]}, 'model_name': 'amazon.nova-pro-v1:0'}, id='run-a2d4c4b9-a6ba-45bd-a492-9936d63b4500-0', tool_calls=[{'name': 'python_repl_ast', 'args': {'query': \"import pandas as pd\\ndf = pd.DataFrame({'Age': [22, 35, 45, 29, 31], 'Fare': [7.25, 14.5, 31.0, 7.925, 26.55]})\\ndf['Age'].corr(df['Fare'])\"}, 'id': 'tooluse_Pdt6-wMOSMmjtVCaLseKPQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 475, 'output_tokens': 196, 'total_tokens': 671})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools([tool], tool_choice=tool.name)\n",
    "response = llm_with_tools.invoke(\n",
    "    \"I have a dataframe 'df' and want to know the correlation between the 'Age' and 'Fare' columns\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28609038-ea66-445d-96c3-63bd8934064e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'python_repl_ast',\n",
       "  'args': {'query': \"import pandas as pd\\ndf = pd.DataFrame({'Age': [22, 35, 45, 29, 31], 'Fare': [7.25, 14.5, 31.0, 7.925, 26.55]})\\ndf['Age'].corr(df['Fare'])\"},\n",
       "  'id': 'tooluse_Pdt6-wMOSMmjtVCaLseKPQ',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c835335d-4b9c-4602-89af-93cfa9da2399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tooluse_Pdt6-wMOSMmjtVCaLseKPQ'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls[0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5cf4135-8fb3-4f85-bbf4-6552d506bf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"import pandas as pd\\ndf = pd.DataFrame({'Age': [22, 35, 45, 60, 28], 'Fare': [7.25, 71.28, 7.92, 53.15, 8.05]})\\ndf.corr()\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers.openai_tools import JsonOutputKeyToolsParser\n",
    "\n",
    "parser = JsonOutputKeyToolsParser(key_name=tool.name, first_tool_only=True)\n",
    "(llm_with_tools | parser).invoke(\n",
    "    \"I have a dataframe 'df' and want to know the correlation between the 'Age' and 'Fare' columns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70548b7f-5aae-4134-8fea-0dcad969c595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"df['Age'].corr(df['Fare'])\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = f\"\"\"You have access to a pandas dataframe `df`. \\\n",
    "Here is the output of `df.head().to_markdown()`:\n",
    "\n",
    "\\`\\`\\`\n",
    "{df.head().to_markdown()}\n",
    "\\`\\`\\`\n",
    "\n",
    "Given a user question, write the Python code to answer it. \\\n",
    "Return ONLY the valid Python code and nothing else. \\\n",
    "Don't assume you have access to any libraries other than built-in Python ones and pandas.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{question}\")])\n",
    "code_chain = prompt | llm_with_tools | parser\n",
    "code_chain.invoke({\"question\": \"What's the correlation between age and fare\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7861a53-7f18-4d0a-b607-b2ad7c9bcc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                              Heikkinen, Miss Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f08b8af-24ea-40ee-8a61-d04e5c155e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "system = f\"\"\"You have access to a pandas dataframe `df`, by running df = pd.read_csv(\"titanic.csv\"). \\\n",
    "Here is the output of `df.head().to_markdown()`:\n",
    "\n",
    "\\`\\`\\`\n",
    "{df.head().to_markdown()}\n",
    "\\`\\`\\`\n",
    "\n",
    "Given a user question, write the Python code to answer it. \\\n",
    "Don't assume you have access to any libraries other than built-in Python ones and pandas.\n",
    "Respond directly to the question once you have enough information to answer it.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system,\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "        # This MessagesPlaceholder allows us to optionally append an arbitrary number of messages\n",
    "        # at the end of the prompt using the 'chat_history' arg.\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb8b8ab8-757a-4355-9526-2ba44f1cd895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7ff5ea5b4ea0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You have access to a pandas dataframe `df`, by running df = pd.read_csv(\"titanic.csv\"). Here is the output of `df.head().to_markdown()`:\\n\\n\\\\`\\\\`\\\\`\\n|    |   PassengerId |   Survived |   Pclass | Name                                                | Sex    |   Age |   SibSp |   Parch | Ticket           |    Fare | Cabin   | Embarked   |\\n|---:|--------------:|-----------:|---------:|:----------------------------------------------------|:-------|------:|--------:|--------:|:-----------------|--------:|:--------|:-----------|\\n|  0 |             1 |          0 |        3 | Braund, Mr. Owen Harris                             | male   |    22 |       1 |       0 | A/5 21171        |  7.25   | nan     | S          |\\n|  1 |             2 |          1 |        1 | Cumings, Mrs. John Bradley (Florence Briggs Thayer) | female |    38 |       1 |       0 | PC 17599         | 71.2833 | C85     | C          |\\n|  2 |             3 |          1 |        3 | Heikkinen, Miss Laina                               | female |    26 |       0 |       0 | STON/O2. 3101282 |  7.925  | nan     | S          |\\n|  3 |             4 |          1 |        1 | Futrelle, Mrs. Jacques Heath (Lily May Peel)        | female |    35 |       1 |       0 | 113803           | 53.1    | C123    | S          |\\n|  4 |             5 |          0 |        3 | Allen, Mr. William Henry                            | male   |    35 |       0 |       0 | 373450           |  8.05   | nan     | S          |\\n\\\\`\\\\`\\\\`\\n\\nGiven a user question, write the Python code to answer it. Don\\'t assume you have access to any libraries other than built-in Python ones and pandas.\\nRespond directly to the question once you have enough information to answer it.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc9b22e2-9afe-4c6c-8e7c-8c9bb476c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_chat_history(x: dict) -> list:\n",
    "    \"\"\"Parse the chain output up to this point into a list of chat history messages to insert in the prompt.\"\"\"\n",
    "    ai_msg = x[\"ai_msg\"]\n",
    "    tool_call_id = ai_msg.tool_calls[0][\"id\"]\n",
    "    tool_msg = ToolMessage(tool_call_id=tool_call_id, content=str(x[\"tool_output\"]))\n",
    "    print([ai_msg, tool_msg])\n",
    "    return [ai_msg, tool_msg]\n",
    "\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(ai_msg=prompt | llm_with_tools)\n",
    "    .assign(tool_output=itemgetter(\"ai_msg\") | parser | tool)\n",
    "    .assign(chat_history=_get_chat_history)\n",
    "    #.assign(response=prompt | llm | StrOutputParser())\n",
    "    .pick([\"tool_output\", \"response\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe0ab485-2a8d-44f8-89a1-c64b9c209e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content=[{'type': 'tool_use', 'name': 'python_repl_ast', 'input': {'query': 'import pandas as pd\\ndf = pd.read_csv(\"titanic.csv\")\\ndf[\\'Age\\'].corr(df[\\'Fare\\'])'}, 'id': 'tooluse_8g-afeaZQ520Z-QR79k6SQ'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '00a5c223-c30b-4754-8e15-747826e303d9', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 21 May 2025 22:44:59 GMT', 'content-type': 'application/json', 'content-length': '359', 'connection': 'keep-alive', 'x-amzn-requestid': '00a5c223-c30b-4754-8e15-747826e303d9'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [502]}, 'model_name': 'amazon.nova-pro-v1:0'}, id='run-167a6529-993d-4e4b-9e81-f668fba17ad3-0', tool_calls=[{'name': 'python_repl_ast', 'args': {'query': 'import pandas as pd\\ndf = pd.read_csv(\"titanic.csv\")\\ndf[\\'Age\\'].corr(df[\\'Fare\\'])'}, 'id': 'tooluse_8g-afeaZQ520Z-QR79k6SQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 957, 'output_tokens': 84, 'total_tokens': 1041}), ToolMessage(content='0.09606669176903888', tool_call_id='tooluse_8g-afeaZQ520Z-QR79k6SQ')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tool_output': 0.09606669176903888}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What's the correlation between age and fare\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "069f4761-bbfb-40ca-946f-fa4c774b8270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"age_fare_corr = df['Age'].corr(df['Fare'])\\nfare_survival_corr = df['Fare'].corr(df['Survived'])\\n(age_fare_corr, fare_survival_corr)\"}`\n",
      "responded: [{'type': 'text', 'text': '<thinking> To determine the correlation between age and fare, and compare it with the correlation between fare and survival, I need to calculate the correlation coefficients for both pairs of columns. The correlation coefficient is a measure of the linear relationship between two variables, ranging from -1 to 1. A value of 1 indicates a strong positive relationship, -1 indicates a strong negative relationship, and 0 indicates no relationship.\\n\\nFirst, I will calculate the correlation between age and fare using the `corr()` function. Then, I will calculate the correlation between fare and survival. Finally, I will compare the two correlation coefficients to determine if the correlation between age and fare is greater than the correlation between fare and survival. </thinking>\\n\\n', 'index': 0}, {'type': 'tool_use', 'name': 'python_repl_ast', 'id': 'tooluse_lKGP9-vvTxWHUjZz9NbbdA', 'index': 1, 'input': '{\"query\":\"age_fare_corr = df[\\'Age\\'].corr(df[\\'Fare\\'])\\\\nfare_survival_corr = df[\\'Fare\\'].corr(df[\\'Survived\\'])\\\\n(age_fare_corr, fare_survival_corr)\"}'}]\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m(0.09606669176903888, 0.25730652238496243)\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'age_fare_corr, fare_survival_corr = [0.09606669176903888, 0.25730652238496243]\\nage_fare_corr > fare_survival_corr'}`\n",
      "responded: [{'type': 'text', 'text': '<thinking> The tool result provides the correlation coefficients for both pairs of columns. The correlation between age and fare is approximately 0.096, and the correlation between fare and survival is approximately 0.257.\\n\\nNow, I need to compare these two correlation coefficients to determine if the correlation between age and fare is greater than the correlation between fare and survival. </thinking> ', 'index': 0}, {'type': 'tool_use', 'name': 'python_repl_ast', 'id': 'tooluse_JQHxOgFoR8OaW1v7Qs-pcw', 'index': 1, 'input': '{\"query\":\"age_fare_corr, fare_survival_corr = [0.09606669176903888, 0.25730652238496243]\\\\nage_fare_corr > fare_survival_corr\"}'}]\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mFalse\u001b[0m\u001b[32;1m\u001b[1;3m[{'type': 'text', 'text': 'The correlation between age and fare is not greater than the correlation between fare and survival. The correlation between age and fare is approximately 0.096, while the correlation between fare and survival is approximately 0.257. Therefore, the correlation between fare and survival is stronger than the correlation between age and fare.', 'index': 0}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the correlation between age and fare? is that greater than the correlation between fare and survival?\",\n",
       " 'output': [{'type': 'text',\n",
       "   'text': 'The correlation between age and fare is not greater than the correlation between fare and survival. The correlation between age and fare is approximately 0.096, while the correlation between fare and survival is approximately 0.257. Therefore, the correlation between fare and survival is stronger than the correlation between age and fare.',\n",
       "   'index': 0}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "\n",
    "agent = create_pandas_dataframe_agent(\n",
    "    llm, df, agent_type=\"openai-tools\", verbose=True, allow_dangerous_code=True\n",
    ")\n",
    "agent.invoke(\n",
    "    {\n",
    "        \"input\": \"What's the correlation between age and fare? is that greater than the correlation between fare and survival?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7615e652-2e29-4670-85b7-692e972c8803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07603993061334446"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df[[\"Age\", \"Fare\"]]\n",
    "df_2 = df[[\"Fare\", \"Survived\"]]\n",
    "\n",
    "tool = PythonAstREPLTool(locals={\"df_1\": df_1, \"df_2\": df_2})\n",
    "llm_with_tool = llm.bind_tools(tools=[tool], tool_choice=tool.name)\n",
    "df_template = \"\"\"\\`\\`\\`python\n",
    "{df_name}.head().to_markdown()\n",
    ">>> {df_head}\n",
    "\\`\\`\\`\"\"\"\n",
    "df_context = \"\\n\\n\".join(\n",
    "    df_template.format(df_head=_df.head().to_markdown(), df_name=df_name)\n",
    "    for _df, df_name in [(df_1, \"df_1\"), (df_2, \"df_2\")]\n",
    ")\n",
    "\n",
    "system = f\"\"\"You have access to a number of pandas dataframes. \\\n",
    "Here is a sample of rows from each dataframe and the python code that was used to generate the sample:\n",
    "\n",
    "{df_context}\n",
    "\n",
    "Given a user question about the dataframes, write the Python code to answer it. \\\n",
    "Don't assume you have access to any libraries other than built-in Python ones and pandas. \\\n",
    "Make sure to refer only to the variables mentioned above.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{question}\")])\n",
    "\n",
    "chain = prompt | llm_with_tool | parser | tool\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"question\": \"return the difference in the correlation between age and fare and the correlation between fare and survival\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b1461-5c30-4776-abbf-a7b48eeeb103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
